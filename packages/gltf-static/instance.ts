import type { EditorSpotlight, EditorEnvironment } from "@gltf-plugins/shared-types";

const PLUGIN_CLASS = SDK.Plugins.GltfStatic;

// Builtin models are loaded via globalThis.GltfBundle.BuiltinModels (from c3runtime/builtin-models.js)
type BuiltinModelType = "cube" | "sphere" | "capsule";

function getBuiltinModelArrayBuffer(type: BuiltinModelType): ArrayBuffer {
	return (globalThis as any).GltfBundle.BuiltinModels.getBuiltinModelArrayBuffer(type);
}

// Property indices (matching plugin.ts order, excluding link properties)
const PROP_MODEL_URL = "model-url";
const PROP_ROTATION_X = "rotation-x";
const PROP_ROTATION_Y = "rotation-y";
const PROP_ROTATION_Z = "rotation-z";
const PROP_SCALE = "scale";
const PROP_USE_BUILTIN = "use-built-in-model";
const PROP_BUILTIN_TYPE = "built-in-model-type";

// Degrees to radians conversion
const DEG_TO_RAD = Math.PI / 180;

// Model loading debug logging
const modelLoadDebug = true;
const LOG_PREFIX = "[GltfStaticEditor]";

function modelLoadLog(...args: unknown[]): void {
	if (modelLoadDebug) console.log(LOG_PREFIX, ...args);
}

function modelLoadWarn(...args: unknown[]): void {
	// Always log warnings (not gated by debug flag)
	console.warn(LOG_PREFIX, ...args);
}

/** Cached editor model with reference count */
interface EditorCacheEntry {
	model: EditorGltfModel;
	refCount: number;
}

/** Model cache keyed by project file path */
const editorModelCache = new Map<string, EditorCacheEntry>();

/** Loading promises for deduplication - prevents concurrent loads of same URL */
const editorModelLoading = new Map<string, Promise<EditorGltfModel>>();

/** Raw mesh data for editor rendering */
interface EditorMeshData {
	positions: Float32Array;  // x, y, z per vertex
	normals: Float32Array | null;  // x, y, z per vertex (null if not available)
	uvs: Float32Array;        // u, v per vertex
	indices: Uint16Array;     // triangle indices
	vertexCount: number;
	textureIndex: number;     // -1 = no texture, otherwise index into model's images array
}

/** glTF accessor types */
interface GltfAccessor {
	bufferView: number;
	byteOffset?: number;
	componentType: number;  // 5126=FLOAT, 5123=UNSIGNED_SHORT, 5125=UNSIGNED_INT, 5121=UNSIGNED_BYTE
	count: number;
	type: string;  // SCALAR, VEC2, VEC3, VEC4
}

interface GltfBufferView {
	buffer: number;
	byteOffset?: number;
	byteLength: number;
	byteStride?: number;
}

interface GltfMeshPrimitive {
	attributes: {
		POSITION?: number;
		NORMAL?: number;
		TEXCOORD_0?: number;
	};
	indices?: number;
	mode?: number;  // 4 = TRIANGLES (default)
	material?: number;
}

interface GltfImage {
	mimeType?: string;
	bufferView?: number;
	uri?: string;
}

interface GltfTexture {
	source?: number;  // index into images array
}

interface GltfMaterial {
	pbrMetallicRoughness?: {
		baseColorTexture?: { index: number };
	};
}

interface GltfMesh {
	primitives: GltfMeshPrimitive[];
}

interface GltfNode {
	mesh?: number;
	children?: number[];
	translation?: number[];
	rotation?: number[];
	scale?: number[];
	matrix?: number[];
}

interface GltfScene {
	nodes?: number[];
}

interface GltfDocument {
	accessors?: GltfAccessor[];
	bufferViews?: GltfBufferView[];
	buffers?: { byteLength: number; uri?: string }[];
	meshes?: GltfMesh[];
	nodes?: GltfNode[];
	scenes?: GltfScene[];
	scene?: number;
	images?: GltfImage[];
	textures?: GltfTexture[];
	materials?: GltfMaterial[];
}

/** Simple 4x4 matrix operations */
function mat4Identity(): Float32Array {
	const m = new Float32Array(16);
	m[0] = m[5] = m[10] = m[15] = 1;
	return m;
}

function mat4Multiply(out: Float32Array, a: Float32Array, b: Float32Array): Float32Array {
	const a00 = a[0], a01 = a[1], a02 = a[2], a03 = a[3];
	const a10 = a[4], a11 = a[5], a12 = a[6], a13 = a[7];
	const a20 = a[8], a21 = a[9], a22 = a[10], a23 = a[11];
	const a30 = a[12], a31 = a[13], a32 = a[14], a33 = a[15];

	let b0 = b[0], b1 = b[1], b2 = b[2], b3 = b[3];
	out[0] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
	out[1] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
	out[2] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
	out[3] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;

	b0 = b[4]; b1 = b[5]; b2 = b[6]; b3 = b[7];
	out[4] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
	out[5] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
	out[6] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
	out[7] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;

	b0 = b[8]; b1 = b[9]; b2 = b[10]; b3 = b[11];
	out[8] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
	out[9] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
	out[10] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
	out[11] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;

	b0 = b[12]; b1 = b[13]; b2 = b[14]; b3 = b[15];
	out[12] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
	out[13] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
	out[14] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
	out[15] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;

	return out;
}

function mat4FromRotationTranslationScale(out: Float32Array, q: number[], t: number[], s: number[]): Float32Array {
	// Quaternion to rotation matrix
	const x = q[0], y = q[1], z = q[2], w = q[3];
	const x2 = x + x, y2 = y + y, z2 = z + z;
	const xx = x * x2, xy = x * y2, xz = x * z2;
	const yy = y * y2, yz = y * z2, zz = z * z2;
	const wx = w * x2, wy = w * y2, wz = w * z2;
	const sx = s[0], sy = s[1], sz = s[2];

	out[0] = (1 - (yy + zz)) * sx;
	out[1] = (xy + wz) * sx;
	out[2] = (xz - wy) * sx;
	out[3] = 0;
	out[4] = (xy - wz) * sy;
	out[5] = (1 - (xx + zz)) * sy;
	out[6] = (yz + wx) * sy;
	out[7] = 0;
	out[8] = (xz + wy) * sz;
	out[9] = (yz - wx) * sz;
	out[10] = (1 - (xx + yy)) * sz;
	out[11] = 0;
	out[12] = t[0];
	out[13] = t[1];
	out[14] = t[2];
	out[15] = 1;

	return out;
}

function transformPoint(out: number[], p: number[], m: Float32Array): void {
	const x = p[0], y = p[1], z = p[2];
	const w = m[3] * x + m[7] * y + m[11] * z + m[15] || 1;
	out[0] = (m[0] * x + m[4] * y + m[8] * z + m[12]) / w;
	out[1] = (m[1] * x + m[5] * y + m[9] * z + m[13]) / w;
	out[2] = (m[2] * x + m[6] * y + m[10] * z + m[14]) / w;
}

/**
 * Editor glTF model - stores parsed mesh data for CPU rendering.
 * Textures are created lazily and shared across all instances using this model.
 */
class EditorGltfModel {
	private _meshes: EditorMeshData[] = [];
	private _images: ImageBitmap[] = [];
	private _isLoaded: boolean = false;

	// Shared textures (created on first draw, reused by all instances)
	private _textures: SDK.Gfx.IWebGLTexture[] = [];
	private _texturesCreated: boolean = false;
	private _lastRenderer: SDK.Gfx.IWebGLRenderer | null = null;

	// Track async texture creation state
	texturesCreating: boolean = false;

	get texturesCreated(): boolean {
		return this._texturesCreated;
	}

	get isLoaded(): boolean {
		return this._isLoaded;
	}

	get meshes(): EditorMeshData[] {
		return this._meshes;
	}

	get images(): ImageBitmap[] {
		return this._images;
	}

	get textures(): SDK.Gfx.IWebGLTexture[] {
		return this._textures;
	}

	/**
	 * Load model from ArrayBuffer (used by editor which gets blob from project file).
	 */
	async loadFromBuffer(arrayBuffer: ArrayBuffer, filename: string): Promise<void> {
		modelLoadLog("Loading from buffer:", filename, arrayBuffer.byteLength, "bytes");
		const loadStart = performance.now();

		try {
			// Detect format from magic bytes or extension
			const isGlb = this._isGlbFormat(arrayBuffer) || filename.toLowerCase().endsWith('.glb');

			if (isGlb) {
				await this._parseGlb(arrayBuffer);
			} else {
				await this._parseGltf(arrayBuffer, filename);
			}

			this._isLoaded = true;
			modelLoadLog(`Load complete in ${(performance.now() - loadStart).toFixed(0)}ms:`, {
				meshCount: this._meshes.length,
				totalVertices: this._meshes.reduce((sum, m) => sum + m.vertexCount, 0)
			});
		} catch (err) {
			modelLoadWarn("Load failed:", err);
			throw err;
		}
	}

	private _isGlbFormat(buffer: ArrayBuffer): boolean {
		const view = new DataView(buffer);
		// GLB magic: 0x46546C67 ("glTF" in little-endian)
		return view.getUint32(0, true) === 0x46546C67;
	}

	private async _parseGlb(buffer: ArrayBuffer): Promise<void> {
		const view = new DataView(buffer);

		// Parse GLB header
		const magic = view.getUint32(0, true);
		if (magic !== 0x46546C67) {
			throw new Error("Invalid GLB magic");
		}

		const version = view.getUint32(4, true);
		if (version !== 2) {
			throw new Error(`Unsupported GLB version: ${version}`);
		}

		// const totalLength = view.getUint32(8, true);
		modelLoadLog("GLB version:", version);

		// Parse chunks
		let offset = 12;
		let jsonData: GltfDocument | null = null;
		let binaryBuffer: ArrayBuffer | null = null;

		while (offset < buffer.byteLength) {
			const chunkLength = view.getUint32(offset, true);
			const chunkType = view.getUint32(offset + 4, true);
			offset += 8;

			if (chunkType === 0x4E4F534A) {  // "JSON"
				const jsonBytes = new Uint8Array(buffer, offset, chunkLength);
				const jsonString = new TextDecoder().decode(jsonBytes);
				jsonData = JSON.parse(jsonString) as GltfDocument;
				modelLoadLog("Parsed JSON chunk");
			} else if (chunkType === 0x004E4942) {  // "BIN\0"
				binaryBuffer = buffer.slice(offset, offset + chunkLength);
				modelLoadLog("Found binary chunk:", chunkLength, "bytes");
			}

			offset += chunkLength;
		}

		if (!jsonData) {
			throw new Error("GLB missing JSON chunk");
		}

		await this._processDocument(jsonData, binaryBuffer ? [binaryBuffer] : []);
	}

	private async _parseGltf(buffer: ArrayBuffer, baseUrl: string): Promise<void> {
		const jsonString = new TextDecoder().decode(buffer);
		const jsonData = JSON.parse(jsonString) as GltfDocument;

		// Load buffers (data URIs or external)
		const buffers: ArrayBuffer[] = [];
		if (jsonData.buffers) {
			for (let i = 0; i < jsonData.buffers.length; i++) {
				const bufferDef = jsonData.buffers[i];
				if (bufferDef.uri && bufferDef.uri.startsWith("data:")) {
					// Handle data URI buffers
					const response = await fetch(bufferDef.uri);
					const arrayBuffer = await response.arrayBuffer();
					buffers[i] = arrayBuffer;
					modelLoadLog(`Buffer ${i}: loaded from data URI (${arrayBuffer.byteLength} bytes)`);
				} else if (bufferDef.uri) {
					// External buffer - not supported yet
					modelLoadWarn(`Buffer ${i}: external buffer loading not implemented, skipping`);
					buffers[i] = new ArrayBuffer(0);
				} else {
					// No URI - might be embedded in GLB binary chunk
					buffers[i] = new ArrayBuffer(0);
				}
			}
		}

		await this._processDocument(jsonData, buffers);
	}

	private async _processDocument(doc: GltfDocument, buffers: ArrayBuffer[]): Promise<void> {
		if (!doc.meshes || doc.meshes.length === 0) {
			modelLoadWarn("No meshes in document");
			return;
		}

		// Decode all embedded images first
		await this._decodeImages(doc, buffers);

		// Process all scenes, or just the default scene
		const sceneIndices = doc.scene !== undefined ? [doc.scene] :
			(doc.scenes ? doc.scenes.map((_, i) => i) : []);

		for (const sceneIdx of sceneIndices) {
			const scene = doc.scenes?.[sceneIdx];
			if (!scene?.nodes) continue;

			for (const nodeIdx of scene.nodes) {
				this._processNode(doc, buffers, nodeIdx, mat4Identity());
			}
		}
	}

	private async _decodeImages(doc: GltfDocument, buffers: ArrayBuffer[]): Promise<void> {
		if (!doc.images || doc.images.length === 0) {
			modelLoadLog("No images in document");
			return;
		}

		modelLoadLog(`Decoding ${doc.images.length} images...`);

		for (let i = 0; i < doc.images.length; i++) {
			const image = doc.images[i];

			try {
				let blob: Blob;

				// Handle data URI images (e.g., "data:image/png;base64,...")
				if (image.uri && image.uri.startsWith("data:")) {
					const response = await fetch(image.uri);
					blob = await response.blob();
					modelLoadLog(`Image ${i}: loaded from data URI`);
				}
				// Handle bufferView images (embedded in binary buffer)
				else if (image.bufferView !== undefined) {
					const bufferView = doc.bufferViews?.[image.bufferView];
					if (!bufferView) {
						modelLoadWarn(`Image ${i}: bufferView not found`);
						this._images[i] = null as unknown as ImageBitmap;
						continue;
					}

					const buffer = buffers[bufferView.buffer];
					if (!buffer) {
						modelLoadWarn(`Image ${i}: buffer not found`);
						this._images[i] = null as unknown as ImageBitmap;
						continue;
					}

					const byteOffset = bufferView.byteOffset || 0;
					const imageData = new Uint8Array(buffer, byteOffset, bufferView.byteLength);
					blob = new Blob([imageData], { type: image.mimeType || 'image/png' });
				}
				else {
					modelLoadWarn(`Image ${i}: no bufferView or data URI (external images not supported)`);
					this._images[i] = null as unknown as ImageBitmap;
					continue;
				}

				const imageBitmap = await createImageBitmap(blob);
				this._images[i] = imageBitmap;
				modelLoadLog(`Image ${i}: ${imageBitmap.width}x${imageBitmap.height}`);
			} catch (err) {
				modelLoadWarn(`Image ${i}: decode failed:`, err);
				this._images[i] = null as unknown as ImageBitmap;
			}
		}
	}

	private _processNode(doc: GltfDocument, buffers: ArrayBuffer[], nodeIdx: number, parentMatrix: Float32Array): void {
		const node = doc.nodes?.[nodeIdx];
		if (!node) return;

		// Compute local matrix
		let localMatrix = mat4Identity();
		if (node.matrix) {
			localMatrix = new Float32Array(node.matrix);
		} else {
			const t = node.translation || [0, 0, 0];
			const r = node.rotation || [0, 0, 0, 1];
			const s = node.scale || [1, 1, 1];
			mat4FromRotationTranslationScale(localMatrix, r, t, s);
		}

		// Compute world matrix
		const worldMatrix = mat4Identity();
		mat4Multiply(worldMatrix, parentMatrix, localMatrix);

		// Process mesh if present
		if (node.mesh !== undefined) {
			const mesh = doc.meshes?.[node.mesh];
			if (mesh) {
				this._processMesh(doc, buffers, mesh, worldMatrix);
			}
		}

		// Recurse to children
		if (node.children) {
			for (const childIdx of node.children) {
				this._processNode(doc, buffers, childIdx, worldMatrix);
			}
		}
	}

	private _processMesh(doc: GltfDocument, buffers: ArrayBuffer[], mesh: GltfMesh, worldMatrix: Float32Array): void {
		for (const primitive of mesh.primitives) {
			// Only process triangles (mode 4 is default)
			if (primitive.mode !== undefined && primitive.mode !== 4) {
				modelLoadWarn("Skipping non-triangle primitive, mode:", primitive.mode);
				continue;
			}

			const meshData = this._extractPrimitive(doc, buffers, primitive, worldMatrix);
			if (meshData) {
				this._meshes.push(meshData);
			}
		}
	}

	private _extractPrimitive(doc: GltfDocument, buffers: ArrayBuffer[], primitive: GltfMeshPrimitive, worldMatrix: Float32Array): EditorMeshData | null {
		const posIdx = primitive.attributes.POSITION;
		const normalIdx = primitive.attributes.NORMAL;
		const uvIdx = primitive.attributes.TEXCOORD_0;
		const idxIdx = primitive.indices;

		if (posIdx === undefined || idxIdx === undefined) {
			modelLoadWarn("Primitive missing POSITION or indices");
			return null;
		}

		// Extract positions
		const positions = this._getAccessorData(doc, buffers, posIdx);
		if (!positions) {
			modelLoadWarn("Failed to extract positions");
			return null;
		}

		// Extract normals (optional)
		let normals: Float32Array | null = null;
		if (normalIdx !== undefined) {
			const normalData = this._getAccessorData(doc, buffers, normalIdx);
			normals = normalData ? new Float32Array(normalData) : null;
		}

		// Extract UVs (optional)
		let uvs: Float32Array;
		if (uvIdx !== undefined) {
			const uvData = this._getAccessorData(doc, buffers, uvIdx);
			uvs = uvData ? new Float32Array(uvData) : new Float32Array(positions.length / 3 * 2);
		} else {
			uvs = new Float32Array(positions.length / 3 * 2);  // Default to 0,0
		}

		// Extract indices
		const indicesData = this._getAccessorData(doc, buffers, idxIdx);
		if (!indicesData) {
			modelLoadWarn("Failed to extract indices");
			return null;
		}

		// Convert indices to Uint16Array (DrawMesh requires Uint16Array)
		let indices: Uint16Array;
		if (indicesData instanceof Uint16Array) {
			indices = indicesData;
		} else if (indicesData instanceof Uint32Array) {
			// Check for index overflow - Uint16 max is 65535
			let maxIndex = 0;
			for (let i = 0; i < indicesData.length; i++) {
				if (indicesData[i] > maxIndex) maxIndex = indicesData[i];
			}
			if (maxIndex > 65535) {
				modelLoadWarn(`Mesh has ${maxIndex} vertices but DrawMesh only supports 65535. Indices will be truncated.`);
			}
			indices = new Uint16Array(indicesData);
		} else if (indicesData instanceof Uint8Array) {
			indices = new Uint16Array(indicesData);
		} else {
			indices = new Uint16Array(indicesData);
		}

		const vertexCount = positions.length / 3;

		// Transform positions by world matrix
		const transformedPositions = new Float32Array(positions.length);
		const tempPoint = [0, 0, 0];
		for (let i = 0; i < vertexCount; i++) {
			const idx = i * 3;
			tempPoint[0] = positions[idx];
			tempPoint[1] = positions[idx + 1];
			tempPoint[2] = positions[idx + 2];
			transformPoint(tempPoint, tempPoint, worldMatrix);
			transformedPositions[idx] = tempPoint[0];
			transformedPositions[idx + 1] = tempPoint[1];
			transformedPositions[idx + 2] = tempPoint[2];
		}

		// Transform normals by world matrix (rotation only, no translation)
		let transformedNormals: Float32Array | null = null;
		if (normals) {
			transformedNormals = new Float32Array(normals.length);
			for (let i = 0; i < vertexCount; i++) {
				const idx = i * 3;
				const nx = normals[idx];
				const ny = normals[idx + 1];
				const nz = normals[idx + 2];

				// Transform normal by rotation part of matrix (3x3 upper-left)
				const tnx = worldMatrix[0] * nx + worldMatrix[4] * ny + worldMatrix[8] * nz;
				const tny = worldMatrix[1] * nx + worldMatrix[5] * ny + worldMatrix[9] * nz;
				const tnz = worldMatrix[2] * nx + worldMatrix[6] * ny + worldMatrix[10] * nz;

				// Normalize the result
				const len = Math.sqrt(tnx * tnx + tny * tny + tnz * tnz);
				if (len > 0) {
					transformedNormals[idx] = tnx / len;
					transformedNormals[idx + 1] = tny / len;
					transformedNormals[idx + 2] = tnz / len;
				} else {
					transformedNormals[idx] = 0;
					transformedNormals[idx + 1] = 0;
					transformedNormals[idx + 2] = 1;
				}
			}
		}

		// Look up texture index from material
		let textureIndex = -1;
		if (primitive.material !== undefined) {
			const material = doc.materials?.[primitive.material];
			const baseColorTexInfo = material?.pbrMetallicRoughness?.baseColorTexture;
			if (baseColorTexInfo !== undefined) {
				const texture = doc.textures?.[baseColorTexInfo.index];
				if (texture?.source !== undefined) {
					textureIndex = texture.source;
				}
			}
		}

		modelLoadLog(`Primitive: ${vertexCount} vertices, ${indices.length / 3} triangles, texture: ${textureIndex}, hasNormals: ${!!transformedNormals}`);

		return {
			positions: transformedPositions,
			normals: transformedNormals,
			uvs: new Float32Array(uvs),
			indices,
			vertexCount,
			textureIndex
		};
	}

	private _getAccessorData(doc: GltfDocument, buffers: ArrayBuffer[], accessorIdx: number): Float32Array | Uint16Array | Uint32Array | Uint8Array | null {
		const accessor = doc.accessors?.[accessorIdx];
		if (!accessor) return null;

		const bufferView = doc.bufferViews?.[accessor.bufferView];
		if (!bufferView) return null;

		const buffer = buffers[bufferView.buffer];
		if (!buffer) return null;

		const byteOffset = (bufferView.byteOffset || 0) + (accessor.byteOffset || 0);

		// Component sizes
		const componentSizes: Record<number, number> = {
			5120: 1,  // BYTE
			5121: 1,  // UNSIGNED_BYTE
			5122: 2,  // SHORT
			5123: 2,  // UNSIGNED_SHORT
			5125: 4,  // UNSIGNED_INT
			5126: 4,  // FLOAT
		};

		// Type element counts
		const typeCounts: Record<string, number> = {
			'SCALAR': 1,
			'VEC2': 2,
			'VEC3': 3,
			'VEC4': 4,
			'MAT2': 4,
			'MAT3': 9,
			'MAT4': 16,
		};

		const componentSize = componentSizes[accessor.componentType] || 4;
		const typeCount = typeCounts[accessor.type] || 1;
		const elementCount = accessor.count * typeCount;

		// Handle interleaved data (byteStride)
		const byteStride = bufferView.byteStride;

		if (byteStride && byteStride !== componentSize * typeCount) {
			// Interleaved - need to extract
			const result = new Float32Array(elementCount);
			const view = new DataView(buffer);

			for (let i = 0; i < accessor.count; i++) {
				const elementOffset = byteOffset + i * byteStride;
				for (let j = 0; j < typeCount; j++) {
					if (accessor.componentType === 5126) {  // FLOAT
						result[i * typeCount + j] = view.getFloat32(elementOffset + j * 4, true);
					}
				}
			}
			return result;
		}

		// Contiguous data - copy to new array to handle alignment issues
		// (typed arrays require byte offset to be multiple of element size)
		const byteLength = elementCount * componentSize;
		const rawBytes = new Uint8Array(buffer, byteOffset, byteLength);

		switch (accessor.componentType) {
			case 5126: { // FLOAT
				const result = new Float32Array(elementCount);
				new Uint8Array(result.buffer).set(rawBytes);
				return result;
			}
			case 5123: { // UNSIGNED_SHORT
				const result = new Uint16Array(elementCount);
				new Uint8Array(result.buffer).set(rawBytes);
				return result;
			}
			case 5125: { // UNSIGNED_INT
				const result = new Uint32Array(elementCount);
				new Uint8Array(result.buffer).set(rawBytes);
				return result;
			}
			case 5121:  // UNSIGNED_BYTE
				return new Uint8Array(rawBytes);
			default:
				modelLoadWarn("Unsupported component type:", accessor.componentType);
				return null;
		}
	}

	/**
	 * Ensure WebGL textures are created from ImageBitmaps.
	 * Called on first draw, textures are then shared by all instances.
	 * Uses CreateDynamicTexture + UpdateTexture (editor SDK pattern).
	 */
	ensureTextures(renderer: SDK.Gfx.IWebGLRenderer): void {
		if (this._texturesCreated || !this._isLoaded) return;

		this._texturesCreated = true;
		this._lastRenderer = renderer;

		const imageCount = this._images.length;
		modelLoadLog(`Creating ${imageCount} shared WebGL textures...`);
		modelLoadLog(`Renderer type: ${renderer?.constructor?.name ?? typeof renderer}`);
		modelLoadLog(`Renderer methods available:`, {
			CreateDynamicTexture: typeof (renderer as unknown as Record<string, unknown>).CreateDynamicTexture,
			UpdateTexture: typeof (renderer as unknown as Record<string, unknown>).UpdateTexture,
			DeleteTexture: typeof (renderer as unknown as Record<string, unknown>).DeleteTexture
		});

		for (let i = 0; i < imageCount; i++) {
			const textureIndex = i; // Capture index for logging
			const img = this._images[i];

			// Log image state before processing
			modelLoadLog(`Texture ${textureIndex}: ImageBitmap state:`, {
				exists: !!img,
				width: img?.width ?? 'N/A',
				height: img?.height ?? 'N/A',
				type: img?.constructor?.name ?? typeof img
			});

			// Skip missing, closed, or invalid ImageBitmaps
			if (!img || img.width === 0 || img.height === 0) {
				this._textures[textureIndex] = null as unknown as SDK.Gfx.IWebGLTexture;
				modelLoadWarn(`Texture ${textureIndex}: skipped - invalid ImageBitmap`);
				continue;
			}

			const imgWidth = img.width;
			const imgHeight = img.height;

			try {
				// Editor SDK: CreateDynamicTexture + UpdateTexture
				// Note: Disable mipMap as it may cause internal "hint" errors in UpdateTexture
				modelLoadLog(`Texture ${textureIndex}: calling CreateDynamicTexture(${imgWidth}, ${imgHeight})`);

				const tex = renderer.CreateDynamicTexture(imgWidth, imgHeight, {
					sampling: "bilinear",
					mipMap: false,
					wrapX: "repeat",
					wrapY: "repeat"
				});

				modelLoadLog(`Texture ${textureIndex}: CreateDynamicTexture returned:`, {
					result: tex,
					type: tex?.constructor?.name ?? typeof tex
				});

				modelLoadLog(`Texture ${textureIndex}: calling UpdateTexture with ImageBitmap ${imgWidth}x${imgHeight}`);
				renderer.UpdateTexture(img, tex, { premultiplyAlpha: false });
				modelLoadLog(`Texture ${textureIndex}: UpdateTexture completed`);

				this._textures[textureIndex] = tex;
				modelLoadLog(`Texture ${textureIndex}: created successfully ${imgWidth}x${imgHeight}`);
			} catch (err) {
				const errorMessage = err instanceof Error ? err.message : String(err);
				const errorStack = err instanceof Error ? err.stack : undefined;
				modelLoadWarn(`Texture ${textureIndex}: creation failed:`, {
					error: errorMessage,
					stack: errorStack,
					imgWidth,
					imgHeight
				});
				this._textures[textureIndex] = null as unknown as SDK.Gfx.IWebGLTexture;
			}
		}

		modelLoadLog(`Texture creation complete: ${this._textures.filter(t => t !== null).length}/${imageCount} succeeded`);
	}

	/**
	 * Release all resources including textures.
	 */
	release(): void {
		// Delete WebGL textures
		if (this._lastRenderer) {
			for (const tex of this._textures) {
				if (tex) this._lastRenderer.DeleteTexture(tex);
			}
		}
		this._textures = [];
		this._texturesCreated = false;
		this._lastRenderer = null;

		// Release mesh data
		this._meshes = [];

		// Close ImageBitmaps to free resources
		for (const img of this._images) {
			if (img) img.close();
		}
		this._images = [];
		this._isLoaded = false;
	}
}

PLUGIN_CLASS.Instance = class GltfStaticEditorInstance extends SDK.IWorldInstanceBase
{
	// Model state (model is shared via cache, textures are on the model)
	_model: EditorGltfModel | null = null;
	_isLoading: boolean = false;
	_lastModelUrl: string = "";
	_layoutView: SDK.UI.ILayoutView | null = null;

	// Transform cache (per-instance since each instance has different position/rotation)
	_transformedMeshes: { positions: Float32Array; normals: Float32Array | null; uvs: Float32Array; indices: Uint16Array; textureIndex: number; vertexCount: number }[] = [];
	_lastTransformKey: string = "";

	constructor(sdkType: SDK.ITypeBase, inst: SDK.IWorldInstance)
	{
		super(sdkType, inst);
	}

	Release(): void
	{
		this._layoutView = null;

		// Release from cache (decrements refCount, textures freed when refCount hits 0)
		if (this._model && this._lastModelUrl)
		{
			this._releaseModelFromCache(this._lastModelUrl);
			this._model = null;
		}
		this._transformedMeshes = [];
	}

	/**
	 * Get the URL to load based on property settings.
	 * Built-in model takes priority over model URL.
	 */
	_getModelUrlToLoad(): string
	{
		const useBuiltin = this._inst.GetPropertyValue(PROP_USE_BUILTIN) as boolean;
		if (useBuiltin)
		{
			const builtinType = this._inst.GetPropertyValue(PROP_BUILTIN_TYPE) as string;
			return `builtin:${builtinType}`;
		}
		return this._inst.GetPropertyValue(PROP_MODEL_URL) as string;
	}

	OnCreate(): void
	{
		// Check if model URL is set and load if so
		const modelUrl = this._getModelUrlToLoad();
		if (modelUrl && !this._isLoading)
		{
			this._loadModel(modelUrl);
		}
	}

	OnPlacedInLayout(): void
	{
		// Load model if URL is set
		const modelUrl = this._getModelUrlToLoad();
		if (modelUrl && !this._model && !this._isLoading)
		{
			this._loadModel(modelUrl);
		}
	}

	/**
	 * Get cached model or load it, handling concurrent requests.
	 * Multiple instances loading the same URL will share one load operation.
	 */
	async _getOrLoadModel(url: string): Promise<EditorGltfModel>
	{
		// Check cache first
		const cached = editorModelCache.get(url);
		if (cached)
		{
			cached.refCount++;
			modelLoadLog(`Cache hit: ${url}, refCount=${cached.refCount}`);
			return cached.model;
		}

		// Check if load already in progress - just wait for it
		const loading = editorModelLoading.get(url);
		if (loading)
		{
			modelLoadLog(`Joining existing load: ${url}`);
			await loading;
			// After load completes, get from cache (handles both success and failure uniformly)
			return this._getOrLoadModel(url);
		}

		// Start new load
		modelLoadLog(`Starting new load: ${url}`);
		const loadPromise = this._doModelLoad(url);
		editorModelLoading.set(url, loadPromise);

		try
		{
			const model = await loadPromise;
			editorModelCache.set(url, { model, refCount: 1 });
			modelLoadLog(`Cached: ${url}, refCount=1`);
			return model;
		}
		finally
		{
			editorModelLoading.delete(url);
		}
	}

	/**
	 * Perform the actual model load from project file or built-in data.
	 */
	async _doModelLoad(url: string): Promise<EditorGltfModel>
	{
		let arrayBuffer: ArrayBuffer;

		// Handle built-in models
		if (url.startsWith("builtin:"))
		{
			const type = url.replace("builtin:", "") as BuiltinModelType;
			arrayBuffer = getBuiltinModelArrayBuffer(type);
			modelLoadLog("Loading built-in model:", type);
		}
		else
		{
			// Load from project file
			const projectFile = this.GetProject().GetProjectFileByExportPath(url);
			if (!projectFile)
			{
				throw new Error(`Project file not found: ${url}`);
			}

			const blob = projectFile.GetBlob();
			arrayBuffer = await blob.arrayBuffer();
		}

		const model = new EditorGltfModel();
		await model.loadFromBuffer(arrayBuffer, url);
		return model;
	}

	/**
	 * Release model reference from cache.
	 * Model is only freed when refCount reaches 0.
	 */
	_releaseModelFromCache(url: string): void
	{
		const entry = editorModelCache.get(url);
		if (!entry) return;

		entry.refCount--;
		modelLoadLog(`Released: ${url}, refCount=${entry.refCount}`);

		if (entry.refCount <= 0)
		{
			entry.model.release();
			editorModelCache.delete(url);
			modelLoadLog(`Deleted from cache: ${url}`);
		}
	}

	/**
	 * Clear current model and release from cache.
	 */
	_clearModel(): void
	{
		if (this._model && this._lastModelUrl)
		{
			this._releaseModelFromCache(this._lastModelUrl);
		}
		this._model = null;
		this._transformedMeshes = [];
		this._lastModelUrl = "";
	}

	/**
	 * Load glTF model from project file with caching.
	 */
	async _loadModel(url: string): Promise<void>
	{
		// Clear if no URL
		if (!url)
		{
			this._clearModel();
			return;
		}

		// Skip if same URL already loaded
		if (url === this._lastModelUrl && this._model?.isLoaded)
		{
			return;
		}

		// Release previous model from cache
		this._clearModel();

		this._isLoading = true;
		this._lastModelUrl = url;

		try
		{
			this._model = await this._getOrLoadModel(url);
			modelLoadLog("Model ready:", url);
		}
		catch (err)
		{
			modelLoadWarn("Load failed:", url, err);
			this._model = null;
		}
		finally
		{
			this._isLoading = false;
			if (this._layoutView)
				this._layoutView.Refresh();
		}
	}

	/**
	 * Build transform key for cache invalidation
	 */
	_getTransformKey(): string
	{
		const x = this._inst.GetX();
		const y = this._inst.GetY();
		const z = this._inst.GetZElevation();
		const w = this._inst.GetWidth();
		const h = this._inst.GetHeight();
		const angle = this._inst.GetAngle();
		const rotX = (this._inst.GetPropertyValue(PROP_ROTATION_X) as number) ?? 0;
		const rotY = (this._inst.GetPropertyValue(PROP_ROTATION_Y) as number) ?? 0;
		const rotZ = (this._inst.GetPropertyValue(PROP_ROTATION_Z) as number) ?? 0;
		const scale = (this._inst.GetPropertyValue(PROP_SCALE) as number) ?? 1;

		return `${x},${y},${z},${w},${h},${angle},${rotX},${rotY},${rotZ},${scale}`;
	}

	/**
	 * Build and apply transform to mesh positions
	 */
	_updateTransformedMeshes(): void
	{
		if (!this._model?.isLoaded) return;

		const transformKey = this._getTransformKey();
		if (transformKey === this._lastTransformKey) return;

		this._lastTransformKey = transformKey;
		this._transformedMeshes = [];

		// Get transform parameters
		const x = this._inst.GetX();
		const y = this._inst.GetY();
		const z = this._inst.GetZElevation();
		const angle = this._inst.GetAngle();
		const rotX = ((this._inst.GetPropertyValue(PROP_ROTATION_X) as number) ?? 0) * DEG_TO_RAD;
		// Y rotation offset by +180 degrees to match runtime orientation
		const rotY = (((this._inst.GetPropertyValue(PROP_ROTATION_Y) as number) ?? 0) + 180) * DEG_TO_RAD;
		const rotZ = ((this._inst.GetPropertyValue(PROP_ROTATION_Z) as number) ?? 0) * DEG_TO_RAD;
		const scale = (this._inst.GetPropertyValue(PROP_SCALE) as number) ?? 1;

		// Build 4x4 transform matrix
		// Order: Scale -> 3D Rotations -> 2D Angle -> Translation
		const cosA = Math.cos(angle), sinA = Math.sin(angle);
		const cosX = Math.cos(rotX), sinX = Math.sin(rotX);
		const cosY = Math.cos(rotY), sinY = Math.sin(rotY);
		const cosZ = Math.cos(rotZ), sinZ = Math.sin(rotZ);

		for (const mesh of this._model.meshes)
		{
			const srcPos = mesh.positions;
			const srcNormals = mesh.normals;
			const dstPos = new Float32Array(srcPos.length);
			const dstNormals = srcNormals ? new Float32Array(srcNormals.length) : null;

			for (let i = 0; i < mesh.vertexCount; i++)
			{
				const idx = i * 3;
				let px = srcPos[idx] * scale;
				let py = srcPos[idx + 1] * scale;
				let pz = srcPos[idx + 2] * scale;

				// Apply rotations in reverse order to match runtime matrix multiplication
				// Runtime does: T * Rangle * Rx * Ry * Rz * S
				// So we apply: Z first, then Y, then X, then angle

				// Rotate around Z axis (3D rotation property)
				let temp = px;
				px = px * cosZ - py * sinZ;
				py = temp * sinZ + py * cosZ;

				// Rotate around Y axis
				temp = px;
				px = px * cosY + pz * sinY;
				pz = -temp * sinY + pz * cosY;

				// Rotate around X axis
				temp = py;
				py = py * cosX - pz * sinX;
				pz = temp * sinX + pz * cosX;

				// Apply 2D angle rotation
				temp = px;
				px = px * cosA - py * sinA;
				py = temp * sinA + py * cosA;

				// Translate
				dstPos[idx] = px + x;
				dstPos[idx + 1] = py + y;
				dstPos[idx + 2] = pz + z;

				// Transform normals (rotation only, no translation or scale)
				if (srcNormals && dstNormals)
				{
					let nx = srcNormals[idx];
					let ny = srcNormals[idx + 1];
					let nz = srcNormals[idx + 2];

					// Apply same rotations as positions

					// Rotate around Z axis
					temp = nx;
					nx = nx * cosZ - ny * sinZ;
					ny = temp * sinZ + ny * cosZ;

					// Rotate around Y axis
					temp = nx;
					nx = nx * cosY + nz * sinY;
					nz = -temp * sinY + nz * cosY;

					// Rotate around X axis
					temp = ny;
					ny = ny * cosX - nz * sinX;
					nz = temp * sinX + nz * cosX;

					// Apply 2D angle rotation
					temp = nx;
					nx = nx * cosA - ny * sinA;
					ny = temp * sinA + ny * cosA;

					// Store (already normalized from source)
					dstNormals[idx] = nx;
					dstNormals[idx + 1] = ny;
					dstNormals[idx + 2] = nz;
				}
			}

			this._transformedMeshes.push({
				positions: dstPos,
				normals: dstNormals,
				uvs: mesh.uvs,
				indices: mesh.indices,
				textureIndex: mesh.textureIndex,
				vertexCount: mesh.vertexCount
			});
		}
	}

	/**
	 * Calculate per-vertex lighting colors for a mesh based on spotlights and environment.
	 * Returns a Float32Array with RGBA values (4 floats per vertex) for use with DrawMesh.
	 * Matches the runtime's calculateMeshLighting pattern from Lighting.ts.
	 */
	_calculateVertexColors(
		mesh: { positions: Float32Array; normals: Float32Array | null; vertexCount: number },
		spotlights: EditorSpotlight[],
		env?: EditorEnvironment
	): Float32Array
	{
		const vertexCount = mesh.vertexCount;
		const colors = new Float32Array(vertexCount * 4);
		const positions = mesh.positions;
		const normals = mesh.normals;

		// If no normals, return white for all vertices
		if (!normals)
		{
			for (let i = 0; i < vertexCount; i++)
			{
				const off4 = i * 4;
				colors[off4] = 1;
				colors[off4 + 1] = 1;
				colors[off4 + 2] = 1;
				colors[off4 + 3] = 1;
			}
			return colors;
		}

		for (let i = 0; i < vertexCount; i++)
		{
			const off3 = i * 3;
			const off4 = i * 4;

			// Vertex position (already in world space from _updateTransformedMeshes)
			const px = positions[off3];
			const py = positions[off3 + 1];
			const pz = positions[off3 + 2];

			// Normal (already transformed in _updateTransformedMeshes)
			const nx = normals[off3];
			const ny = normals[off3 + 1];
			const nz = normals[off3 + 2];

			// Start with ambient from environment
			let r = 0, g = 0, b = 0;
			if (env)
			{
				r = env.ambientColor[0] * env.ambientIntensity;
				g = env.ambientColor[1] * env.ambientIntensity;
				b = env.ambientColor[2] * env.ambientIntensity;

				// Hemisphere lighting: blend sky/ground based on normal Z (matches runtime)
				if (env.hemisphereEnabled)
				{
					const blend = (nz + 1) * 0.5;  // Maps [-1, 1] to [0, 1]
					const invBlend = 1 - blend;
					const hemi = env.hemisphereIntensity;
					r += (env.groundColor[0] * invBlend + env.skyColor[0] * blend) * hemi;
					g += (env.groundColor[1] * invBlend + env.skyColor[1] * blend) * hemi;
					b += (env.groundColor[2] * invBlend + env.skyColor[2] * blend) * hemi;
				}
			}
			else
			{
				// Default ambient if no environment
				r = g = b = 0.3;
			}

			// Spotlight contributions (matches runtime calculateMeshLighting)
			for (let j = 0; j < spotlights.length; j++)
			{
				const spot = spotlights[j];
				if (!spot.enabled) continue;

				// Vector from light to vertex
				const dx = px - spot.position[0];
				const dy = py - spot.position[1];
				const dz = pz - spot.position[2];
				const distSq = dx * dx + dy * dy + dz * dz;
				const dist = Math.sqrt(distSq);

				if (dist < 0.0001) continue;  // Avoid division by zero

				// Normalize direction from light to vertex
				const invDist = 1 / dist;
				const toVertX = dx * invDist;
				const toVertY = dy * invDist;
				const toVertZ = dz * invDist;

				// Angular falloff: dot product of spot direction and light-to-vertex
				const cosAngle = spot.direction[0] * toVertX +
				                 spot.direction[1] * toVertY +
				                 spot.direction[2] * toVertZ;

				// Cone angle cosines
				const innerCos = Math.cos(spot.innerAngle * DEG_TO_RAD);
				const outerCos = Math.cos(spot.outerAngle * DEG_TO_RAD);

				// Outside outer cone - no contribution
				if (cosAngle <= outerCos) continue;

				// Angular attenuation
				let angularAtten: number;
				if (cosAngle >= innerCos)
				{
					angularAtten = 1;  // Inside inner cone
				}
				else
				{
					// Penumbra falloff
					const t = (cosAngle - outerCos) / (innerCos - outerCos);
					angularAtten = t;  // Linear falloff (runtime uses pow with falloffExponent)
				}

				// Distance attenuation
				let distAtten = 1;
				if (spot.range > 0)
				{
					if (dist >= spot.range) continue;
					const normalizedDist = dist / spot.range;
					const rangeAtten = 1 - normalizedDist * normalizedDist;
					distAtten = rangeAtten * rangeAtten;
				}
				else
				{
					// Inverse square falloff
					distAtten = 1 / (1 + distSq);
				}

				// NÂ·L: direction FROM vertex TO light is negative of toVert
				const lightDirX = -toVertX;
				const lightDirY = -toVertY;
				const lightDirZ = -toVertZ;
				const NdotL = nx * lightDirX + ny * lightDirY + nz * lightDirZ;

				if (NdotL > 0)
				{
					const contrib = NdotL * spot.intensity * angularAtten * distAtten;
					r += spot.color[0] * contrib;
					g += spot.color[1] * contrib;
					b += spot.color[2] * contrib;
				}
			}

			// Write output (clamped to 2.0 like runtime, allows overbright)
			colors[off4] = r > 2 ? 2 : r;
			colors[off4 + 1] = g > 2 ? 2 : g;
			colors[off4 + 2] = b > 2 ? 2 : b;
			colors[off4 + 3] = 1;
		}

		return colors;
	}

	Draw(iRenderer: SDK.Gfx.IWebGLRenderer, iDrawParams: SDK.Gfx.IDrawParams): void
	{
		// Store layout view for refresh after async loads
		this._layoutView = iDrawParams.GetLayoutView();

		// If model is loaded, render it
		if (this._model?.isLoaded)
		{
			// Update transformed positions if needed
			this._updateTransformedMeshes();

			// Create textures if not done (synchronous in editor SDK)
			if (!this._model.texturesCreated && !this._model.texturesCreating)
			{
				this._model.texturesCreating = true;
				this._model.ensureTextures(iRenderer);
			}

			// Get editor lighting state
			const spotlights = globalThis.gltfEditorSpotlights ?? [];
			const env = globalThis.gltfEditorEnvironment;

			// Draw each mesh using shared textures from the model
			for (const mesh of this._transformedMeshes)
			{
				const tex = mesh.textureIndex >= 0 ? this._model.textures[mesh.textureIndex] : null;

				// Calculate per-vertex colors if lighting exists and mesh has normals
				let vertexColors: Float32Array | undefined;
				const hasLighting = (spotlights.length > 0 || env) && mesh.normals;

				if (hasLighting)
				{
					vertexColors = this._calculateVertexColors(mesh, spotlights, env);
				}

				if (tex)
				{
					iRenderer.SetTextureFillMode();
					iRenderer.SetTexture(tex);
				}
				else
				{
					iRenderer.SetColorFillMode();
				}

				// Default gray when no vertex colors
				if (!vertexColors)
				{
					iRenderer.SetColorRgba(0.7, 0.7, 0.7, 1);
				}

				iRenderer.DrawMesh(mesh.positions, mesh.uvs, mesh.indices, vertexColors);
			}
		}
		else
		{
			// Fallback: draw placeholder while loading or if no model
			// Just draw a simple colored rectangle - avoid Quad3 which requires valid texRect
			iRenderer.SetColorFillMode();
			iRenderer.SetColorRgba(0.25, 0.25, 0.5, 1);
			const quad = this._inst.GetQuad();
			if (quad)
			{
				iRenderer.Quad(quad);
			}
		}
	}

	OnMakeOriginalSize(): void
	{
		const objectType = this.GetObjectType();
		const image = objectType.GetImage();
		const width = image.GetWidth();
		const height = image.GetHeight();

		if (width > 0 && height > 0)
		{
			this._inst.SetSize(width, height);
		}
	}

	OnDoubleTap(): void
	{
		this.GetObjectType().EditImage();
	}

	HasDoubleTapHandler(): boolean
	{
		return true;
	}

	OnPropertyChanged(id: string, value: EditorPropertyValueType): void
	{
		// Reload model if URL changed (only if not using built-in model)
		if (id === PROP_MODEL_URL)
		{
			const useBuiltin = this._inst.GetPropertyValue(PROP_USE_BUILTIN) as boolean;
			if (!useBuiltin)
			{
				const url = value as string;
				if (url !== this._lastModelUrl)
				{
					this._loadModel(url);
				}
			}
		}

		// Handle built-in model property changes
		if (id === PROP_USE_BUILTIN || id === PROP_BUILTIN_TYPE)
		{
			const newUrl = this._getModelUrlToLoad();
			if (newUrl !== this._lastModelUrl)
			{
				this._loadModel(newUrl);
			}
		}

		// Clear transform cache when any transform property changes
		// This will force recalculation on next Draw
		if (id === PROP_ROTATION_X || id === PROP_ROTATION_Y ||
			id === PROP_ROTATION_Z || id === PROP_SCALE)
		{
			this._lastTransformKey = "";
		}
	}

	LoadC2Property(name: string, valueString: string): boolean
	{
		return false;
	}
};

export type SDKEditorInstanceClass = InstanceType<typeof PLUGIN_CLASS.Instance>;
